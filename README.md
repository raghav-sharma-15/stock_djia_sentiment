# Stock Sentiment + DJIA Prediction Pipeline

This repository contains code and data to:
1. Load and preprocess the **Combined_News_DJIA** dataset.
2. Compute FinBERT sentiment for each daily news headline.
3. Calculate technical indicators (Return, EMA, SMA, RSI, ATR, Volume lag).
4. Merge sentiment + technical features and train an XGBoost classifier to predict the next-day DJIA direction (Up vs. Down).
5. Run inference on the merged features and generate predictions.

---

## Repository Structure

```
your-repo-name/
├── .gitignore
├── README.md
├── requirements.txt
├── main.py
├── src/
│   ├── __pycache__.py
│   ├── data_loader.py
│   ├── sentiment_extractor.py
│   ├── feature_engineering.py
│   ├── train_model.py
│   └── predict.py
├── data/
│   ├── Combined_News_DJIA.csv          # Original DJIA news dataset
│   ├── djia_merged_features.csv        # Merged sentiment + technical features
│   └── djia_predictions.csv            # Model predictions on merged features
└── models/
    └── xgb_djia_sentiment_model.joblib  # Trained XGBoost model
```

- **`.gitignore`**: Lists files and folders for Git to ignore (e.g., virtual environment, OS‐generated files).
- **`README.md`**: This file.
- **`requirements.txt`**: All pip dependencies needed to run the code.
- **`main.py`**: Entry point that
  1. Loads and “melts” the DJIA news CSV (`data/Combined_News_DJIA.csv`).
  2. Fetches DJIA prices via `yfinance`.
  3. Computes technical indicators.
  4. Runs FinBERT sentiment on every headline.
  5. Aggregates daily sentiment, merges with price features, and saves to `data/djia_merged_features.csv`.
  6. Trains an XGBoost model and saves it to `models/xgb_djia_sentiment_model.joblib`.
- **`src/data_loader.py`**: Functions to load & melt the raw CSV and download `^DJI` price data.
- **`src/sentiment_extractor.py`**: Wraps ProsusAI/finbert (FinBERT) to assign `pos`, `neg`, `neu` probabilities per headline.
- **`src/feature_engineering.py`**: Computes technical indicators (Return, EMA_10, SMA_20, RSI_14, ATR_14, Volume_lag1) and merges sentiment.
- **`src/train_model.py`**: Trains an XGBoost classifier using time-series cross-validation (CV). Forces single-threaded execution to avoid segmentation faults on macOS.
- **`src/predict.py`**: Loads the saved model (`.joblib`) and runs inference on a feature CSV, producing `pred_prob` and `pred_label`.

---

## Data Files (in `data/`)

1. **`Combined_News_DJIA.csv`**  
   - The original DJIA news dataset (2008–2016).  
   - Columns:  
     ```
     Date, Label, Top1, Top2, …, Top25
     ```  
   - “Label” is 1 if DJIA went up the next trading day; 0 if it went down.

2. **`djia_merged_features.csv`**  
   - Generated by running `main.py`.  
   - Contains daily rows with columns:  
     ```
     date, label, pos_avg, neg_avg, neu_avg,
     Open, High, Low, Close, Volume, Return,
     EMA_10, SMA_20, RSI_14, ATR_14, Volume_lag1
     ```
   - Merges sentiment averages (`pos_avg`, `neg_avg`, `neu_avg`) with technical indicators for each date.

3. **`djia_predictions.csv`**  
   - Generated by running `src/predict.py`.  
   - Contains all columns from `djia_merged_features.csv` plus:  
     ```
     pred_prob, pred_label
     ```
   - `pred_prob` is the model’s probability that DJIA goes up next day; `pred_label` is 0 (Down) or 1 (Up).

---

## Setup Instructions

1. **Clone the repository:**
   ```bash
   git clone https://github.com/<your-username>/<your-repo-name>.git
   cd <your-repo-name>
   ```

2. **Create and activate a virtual environment:**
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install dependencies:**
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

4. **Run the end-to-end pipeline** (this regenerates `djia_merged_features.csv` and retrains the model):
   ```bash
   python main.py
   ```
   - This reads `data/Combined_News_DJIA.csv`, fetches `^DJI` prices, computes features, and trains `xgb_djia_sentiment_model.joblib` in `models/`.

5. **Run inference** (this regenerates `djia_predictions.csv`):
   ```bash
   python src/predict.py      --model_path models/xgb_djia_sentiment_model.joblib      --features_csv data/djia_merged_features.csv      --output_csv data/djia_predictions.csv
   ```

---

## Quick Eval

To evaluate model performance on the training data:

```bash
python - <<EOF
import pandas as pd
import joblib
from sklearn.metrics import classification_report, confusion_matrix

# Load model and features
model = joblib.load("models/xgb_djia_sentiment_model.joblib")
df = pd.read_csv("data/djia_merged_features.csv", parse_dates=["date"])

# Prepare X, y
feature_cols = [
    "pos_avg", "neg_avg", "neu_avg",
    "Return", "RSI_14", "EMA_10", "SMA_20", "ATR_14", "Volume_lag1"
]
X = df[feature_cols].values
y_true = df["label"].values

# Predict
y_pred = model.predict(X)

# Report
print(classification_report(y_true, y_pred, target_names=["Down", "Up"]))
print("Confusion Matrix:")
print(confusion_matrix(y_true, y_pred))
EOF
```

---

## Simple Backtest Example

```bash
python - <<EOF
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("data/djia_predictions.csv", parse_dates=["date"])

# Next-day return
df["Return_next"] = df["Return"].shift(-1)

# Strategy: go long if prediction is Up (pred_label=1)
df["strat_return"] = df["pred_label"] * df["Return_next"]
df["bh_return"] = df["Return_next"]

# Cumulative returns
df = df.dropna(subset=["Return_next"])
df["strat_cum"] = (1 + df["strat_return"]).cumprod()
df["bh_cum"] = (1 + df["bh_return"]).cumprod()

print("Buy & Hold final:", df["bh_cum"].iloc[-1])
print("Strategy final:", df["strat_cum"].iloc[-1])

# Plot
plt.plot(df["date"], df["bh_cum"], label="Buy & Hold")
plt.plot(df["date"], df["strat_cum"], label="Model Strategy")
plt.legend()
plt.show()
EOF
```

---

## Notes

- The repository includes **all data files** (`Combined_News_DJIA.csv`, `djia_merged_features.csv`, `djia_predictions.csv`).  
- If you regenerate data by running `main.py` / `predict.py`, these files will be overwritten.  
- Feel free to add new features in `src/feature_engineering.py` or tune hyperparameters in `src/train_model.py`.

---

## License

*(Add your preferred license here)*

---

## Acknowledgments

- [Carnegie Mellon’s DJIA News Dataset](https://www.kaggle.com/datasets/aaron7sun/stocknews)  
- [ProsusAI/finbert on Hugging Face](https://huggingface.co/ProsusAI/finbert)  
- [yfinance](https://github.com/ranaroussi/yfinance) for OHLCV data  
- [XGBoost](https://github.com/dmlc/xgboost) for tree-based modeling
